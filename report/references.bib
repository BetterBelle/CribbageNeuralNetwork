@InProceedings{adaptive_cribbage_player,
  author="Kendall, Graham
  and Shaw, Stephen",
  editor="Schaeffer, Jonathan
  and M{\"u}ller, Martin
  and Bj{\"o}rnsson, Yngvi",
  title="Investigation of an Adaptive Cribbage Player",
  booktitle="Computers and Games",
  year="2003",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="29--41",
  abstract="Cribbage is (normally) a two-player card game where the aim is to score 121 points before your opponent. The game has four stages, one of which involves discarding two cards from the six cards you are dealt. A later stage scores the four cards in your hand together with a card cut randomly from the deck after the discards have been made. The two cards that were discarded are used to form another hand, when combined with the two discards from your opponent. This additional hand is referred to as the crib or box and is scored alternatively by you and your opponent. In this work, we investigate how a strategy can be evolved that decides which cards should be discarded into the crib. Several methods are investigated with the best one being compared against a commercially available program.",
  isbn="978-3-540-40031-8"
}

@article{deepmind_2015,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}


@misc{cribbage_rules, 
    title={Learn to Play Cribbage}, 
    url={https://bicyclecards.com/how-to-play/cribbage/}, 
    journal={Cribbage}, 
    author={Bicycle Cards}, 
    year={2022}
}

@Inbook{reinforcement_learning,
  author="van Otterlo, Martijn
  and Wiering, Marco",
  title="Reinforcement Learning and Markov Decision Processes",
  bookTitle="Reinforcement Learning: State-of-the-Art",
  year="2012",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="3--42",
  abstract="Situated in between supervised learning and unsupervised learning, the paradigm of reinforcement learning deals with learning in sequential decision making problems in which there is limited feedback. This text introduces the intuitions and concepts behind Markov decision processes and two classes of algorithms for computing optimal behaviors: reinforcement learning and dynamic programming. First the formal framework of Markov decision process is defined, accompanied by the definition of value functions and policies. The main part of this text deals with introducing foundational classes of algorithms for learning optimal behaviors, based on various definitions of optimality with respect to the goal of learning sequential decisions. Additionally, it surveys efficient extensions of the foundational algorithms, differing mainly in the way feedback given by the environment is used to speed up learning, and in the way they concentrate on relevant parts of the problem. For both model-based and model-free settings these efficient extensions have shown useful in scaling up to larger problems.",
  isbn="978-3-642-27645-3",
  doi="10.1007/978-3-642-27645-3_1",
  url="https://doi.org/10.1007/978-3-642-27645-3_1"
}

@article{bellman,
  title={A Markovian decision process},
  author={Bellman, Richard},
  journal={Journal of mathematics and mechanics},
  pages={679--684},
  year={1957},
  publisher={JSTOR}
}

@article{temp_diff_analysis,
  title={An analysis of temporal-difference learning with function approximation},
  author={Van Roy, Benjamin and others},
  journal={Automatic Control, IEEE Transactions on},
  volume={42},
  number={5},
  pages={674--690},
  year={1997}
}

@misc{cribbage_rules_montana, 
  title={Six Card Cribbage}, 
  url={https://www.cs.montana.edu/users/paxton/cribbage.html}, 
  journal={Six Card Cribbage}, 
  author={Paxton, John}, 
  year={1995}
}

@misc{td_learning_cribbage, 
    title={Temporal Difference Reinforcement Learning Applied to Cribbage}, 
    url={http://r6.ca/cs486/},
    author={O'Connor, Russel}, 
    year={2000}
}

@article{drl_survey,  
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},   
  title={Deep Reinforcement Learning: A Brief Survey},   
  year={2017},  
  volume={34},  
  number={6},  
  pages={26-38},  
  doi={10.1109/MSP.2017.2743240}
}



